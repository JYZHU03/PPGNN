ppgnn:
  model:
    hidden: 256
    layers: 12
    dt: 0.08
    dropout: 0.2
    norm_type: "sym"
    jacobi_steps: 2
    use_x_only: false
    y0_mode: "learned"
    alpha0: 0.2
    beta0: 0.1
    dx0: 0.7
    dy0: 0.8
    norm: "BatchNorm1d"
    lift_type: "mlp"
    lift_layers: 3
    custom: 1
    custom_gnn: "gcn"
    heads: 1
    # FA-LV
    fa_lv: 1
    fa_power: 1.0
    fa_alpha1: 1.0
    fa_beta1: 1.0
    fa_gamma1: 1.0
    fa_delta1: 1.0
    fa_dx1: 1.0
    fa_dy1: 1.0
  train:
    epochs: 2
    lr: 0.001
    weight_decay: 0.0005
    clip_value: 5.0
